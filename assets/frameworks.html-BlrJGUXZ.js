import{_ as r,c as t,a,o as p}from"./app-B6vXTniy.js";const o={};function i(s,e){return p(),t("div",null,[...e[0]||(e[0]=[a('<h1 id="一些爬虫常用框架" tabindex="-1"><a class="header-anchor" href="#一些爬虫常用框架"><span>一些爬虫常用框架</span></a></h1><h2 id="beautiful-soup" tabindex="-1"><a class="header-anchor" href="#beautiful-soup"><span>Beautiful Soup</span></a></h2><p>名气大，整合了一些常用爬虫需求。缺点：不能加载JS</p><h2 id="scrapy" tabindex="-1"><a class="header-anchor" href="#scrapy"><span>Scrapy</span></a></h2><p>看起来很强大的爬虫框架，可以满足简单的页面爬取（比如可以明确获知url pattern的情况）。用这个框架可以轻松爬下来如亚马逊商品信息之类的数据。但是对于稍微复杂一点的页面，如weibo的页面信息，这个框架就满足不了需求了。</p><p>在学会了手写爬虫之后，你会发现爬虫框架会让你省事一万倍。框架中的各种参数都已经设置好，我们只需要改动些许参数，就能够事半功倍。</p><p>Scrapy主要包括了以下组件：</p><ul><li>引擎(Scrapy): 用来处理整个系统的数据流处理, 触发事务(框架核心)</li><li>调度器(Scheduler): 用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL（抓取网页的网址或者说是链接）的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址</li><li>下载器(Downloader): 用于下载网页内容, 并将网页内容返回给蜘蛛(Scrapy下载器是建立在twisted这个高效的异步模型上的)</li><li>爬虫(Spiders): 爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面</li><li>项目管道(Pipeline): 负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据。</li><li>下载器中间件(Downloader Middlewares): 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。</li><li>爬虫中间件(Spider Middlewares): 介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。</li><li>调度中间件(Scheduler Middewares): 介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。</li></ul><p>Scrapy运行流程大概如下：</p><ul><li>首先，引擎从调度器中取出一个链接(URL)用于接下来的抓取</li><li>引擎把URL封装成一个请求(Request)传给下载器，下载器把资源下载下来，并封装成应答包(Response)</li><li>然后，爬虫解析Response</li><li>若是解析出实体（Item）,则交给实体管道进行进一步的处理。</li><li>若是解析出的是链接（URL）,则把URL交给Scheduler等待抓取</li></ul><h2 id="requests和httpx" tabindex="-1"><a class="header-anchor" href="#requests和httpx"><span>requests和httpx</span></a></h2><p>这两个是请求用的,类似nodejs的fetch和axios,一般搭配bs4等进行解析 requests + beautifulsoup4 + lxml 完美组合</p><h2 id="selenium" tabindex="-1"><a class="header-anchor" href="#selenium"><span>selenium</span></a></h2><p>这是一个调用浏览器的driver，通过这个库你可以直接调用浏览器完成某些操作，比如输入验证码。</p><h2 id="puppeteer" tabindex="-1"><a class="header-anchor" href="#puppeteer"><span>Puppeteer</span></a></h2><p><a href="https://pptr.dev/" target="_blank" rel="noopener noreferrer">官网</a><a href="https://github.com/puppeteer/puppeteer" target="_blank" rel="noopener noreferrer">https://github.com/puppeteer/puppeteer</a> 类似selenium 2017年，谷歌公开发布了 Puppeteer，跟进了无头 Chrome 。Chrome DevTools 团队开发了它，使其比其他类似项目具有重大优势，因为它得到了世界上使用最广泛的浏览器的同一家公司的机构支持。</p><p>Puppeteer 可以驱动 Chrome 或 Chromium（所基于Chrome的开源浏览器），默认情况下，安装 Puppeteer 还会下载兼容版本的 Chromium。这避免了您的浏览器最终获得破坏 Puppeteer 的更新的其他可能情况。</p><h2 id="playwright" tabindex="-1"><a class="header-anchor" href="#playwright"><span>playwright</span></a></h2><p><a href="https://playwright.dev/" target="_blank" rel="noopener noreferrer">官网</a><a href="https://github.com/microsoft/playwright" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/playwright</a></p><h2 id="pyspider" tabindex="-1"><a class="header-anchor" href="#pyspider"><span>pyspider</span></a></h2><p><a href="http://docs.pyspider.org/en/latest/" target="_blank" rel="noopener noreferrer">http://docs.pyspider.org/en/latest/</a> PySpider是binux做的一个爬虫架构的开源化实现。主要的功能需求是</p><ul><li>抓取、更新调度多站点的特定的页面</li><li>需要对页面进行结构化信息提取</li><li>灵活可扩展，稳定可监控</li></ul><h2 id="jsoup" tabindex="-1"><a class="header-anchor" href="#jsoup"><span>jsoup</span></a></h2><p><a href="https://jsoup.org/" target="_blank" rel="noopener noreferrer">官网</a> 一个java爬虫</p><h2 id="colly" tabindex="-1"><a class="header-anchor" href="#colly"><span>colly</span></a></h2><p>一个go语言爬虫</p><p><a href="http://go-colly.org/" target="_blank" rel="noopener noreferrer">http://go-colly.org/</a></p><h2 id="goquery" tabindex="-1"><a class="header-anchor" href="#goquery"><span>goquery</span></a></h2><p><a href="https://github.com/PuerkitoBio/goquery" target="_blank" rel="noopener noreferrer">https://github.com/PuerkitoBio/goquery</a></p><h2 id="gospider" tabindex="-1"><a class="header-anchor" href="#gospider"><span>gospider</span></a></h2><p><a href="https://github.com/zhshch2002/gospider" target="_blank" rel="noopener noreferrer">https://github.com/zhshch2002/gospider</a></p>',31)])])}const h=r(o,[["render",i]]),l=JSON.parse('{"path":"/python-tutor/spider/frameworks.html","title":"一些爬虫常用框架","lang":"zh-CN","frontmatter":{"description":"一些爬虫常用框架 Beautiful Soup 名气大，整合了一些常用爬虫需求。缺点：不能加载JS Scrapy 看起来很强大的爬虫框架，可以满足简单的页面爬取（比如可以明确获知url pattern的情况）。用这个框架可以轻松爬下来如亚马逊商品信息之类的数据。但是对于稍微复杂一点的页面，如weibo的页面信息，这个框架就满足不了需求了。 在学会了手写...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"一些爬虫常用框架\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-01-20T13:56:22.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"yzqdev\\",\\"url\\":\\"http://www.yzqdev.top\\"}]}"],["meta",{"property":"og:url","content":"https://yzqdev.github.io/cs-guide/cs-guide/python-tutor/spider/frameworks.html"}],["meta",{"property":"og:site_name","content":"cs-guide"}],["meta",{"property":"og:title","content":"一些爬虫常用框架"}],["meta",{"property":"og:description","content":"一些爬虫常用框架 Beautiful Soup 名气大，整合了一些常用爬虫需求。缺点：不能加载JS Scrapy 看起来很强大的爬虫框架，可以满足简单的页面爬取（比如可以明确获知url pattern的情况）。用这个框架可以轻松爬下来如亚马逊商品信息之类的数据。但是对于稍微复杂一点的页面，如weibo的页面信息，这个框架就满足不了需求了。 在学会了手写..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-01-20T13:56:22.000Z"}],["meta",{"property":"article:modified_time","content":"2023-01-20T13:56:22.000Z"}]]},"git":{"createdTime":1649060661000,"updatedTime":1674222982000,"contributors":[{"name":"yzqdev","username":"yzqdev","email":"yzqdev@outlook.com","commits":3,"url":"https://github.com/yzqdev"}]},"readingTime":{"minutes":3.5,"words":1049},"filePathRelative":"python-tutor/spider/frameworks.md","autoDesc":true}');export{h as comp,l as data};
